{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Aplicação de técnicas de classificação de texto na arquitetura de Chatbots hierárquicos**\n",
    "\n",
    "**Mestrado Profissional em Computação Aplicada - PPCA - Universidade de Brasília**\n",
    "\n",
    "**Disciplina**: Mineração de Dados\n",
    "\n",
    "**Orientador**: Prof. Dr. Marcelo Ladeira <mladeira@unb.br>\n",
    "\n",
    "**Alunos**: \n",
    " - José Ronaldo Agra De Souza Filho <jose.agra@aluno.unb.br>\n",
    " - Bruno Gomes Resende <bruno.resende@aluno.unb.br>\n",
    " - Célio Castro Wermelinger <celio.wermelinger@aluno.unb.br> \n",
    "\n",
    "**Palavras-Chave:**\n",
    "\n",
    "Chatbot; Text Classification; Machine Learning; Text Mining; NLP;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Install packages\n",
    "# Note: use Python 3.8 env\n",
    "#!pip install --pre pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pycaret.classification import *\n",
    "import pandas as pd\n",
    "\n",
    "# download das stopwords para o idioma português\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Montagem do dataset\n",
    "df_covid = pd.read_csv('data/exemplos-treinamento-covid.csv', delimiter=';')\n",
    "df_seloturismo = pd.read_csv('data/exemplos-treinamento-seloturismo.csv', delimiter=';')\n",
    "df_tuberculose = pd.read_csv('data/exemplos-treinamento-tuberculose.csv', delimiter=';')\n",
    "df_teste = pd.read_csv('data/dados-testes-experimentos.csv', delimiter=';')\n",
    "\n",
    "df_all = pd.concat([df_covid, df_seloturismo, df_tuberculose, df_teste], axis=0)\n",
    "df_all.reset_index(drop=True, inplace=True)\n",
    "df_all['category'] = df_all.reset_index().category.map({'covid':0, 'seloturismo':1, 'tuberculose':2})\n",
    "\n",
    "df_all.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# recupera as stopwords do idioma português\n",
    "stop_words = stopwords.words('portuguese')\n",
    "\n",
    "# vetorização das palavras\n",
    "tv = TfidfVectorizer(lowercase=True, stop_words=stop_words, strip_accents='unicode', token_pattern=\"[A-Za-z]+\")\n",
    "\n",
    "tf_idf_dados = tv.fit_transform(df_all['input'])\n",
    "\n",
    "# vetorização para o dataframe referente à categoria COVID\n",
    "df_dados_vetorizados = pd.DataFrame(tf_idf_dados.toarray(), columns=tv.get_feature_names())\n",
    "df_dados_vetorizados['target_cat'] = df_all.reset_index().category\n",
    "\n",
    "dados_treino_validacao = df_dados_vetorizados.sample(frac=0.8, random_state=786).reset_index(drop=True)\n",
    "dados_teste = df_dados_vetorizados.drop(dados_treino_validacao.index).reset_index(drop=True)\n",
    "\n",
    "print('Data for Modeling: ' + str(dados_treino_validacao.shape))\n",
    "print('Unseen Data For Predictions: ' + str(dados_teste.shape))\n",
    "\n",
    "dados_treino_validacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup\n",
    "# Iniciando os recursos da biblioteca, passando como alvo a coluna 'class' do dataset\n",
    "setup = setup(data=dados_treino_validacao, target='target_cat', session_id=20221,\n",
    "              train_size = 0.7, test_data=dados_teste, fold=10, silent=True, fix_imbalance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metricas = get_metrics()\n",
    "metricas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Gerando modelos com diferentes abordagens e escolhendo o melhor por cross-validation\n",
    "modelos = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Imprimindo melhor modelo\n",
    "print(modelos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Matriz de confusão TF-IDF\n",
    "modelo = create_model('et')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# realiza o ensemble dos modelos e seleciona o melhor\n",
    "melhor_modelo_bagging = ensemble_model(modelo, choose_better=True, return_train_score=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Imprimindo melhor modelo\n",
    "print(melhor_modelo_bagging)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_model(melhor_modelo_bagging, plot = 'confusion_matrix')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Realizando predição com dateset de validação\n",
    "predict_model(modelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modelo_final = finalize_model(melhor_modelo_bagging)\n",
    "predicoes = predict_model(modelo_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "predicoes.head(200)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_model(modelo_final,'models/20220914-modelo-final-multiclasses-tdidf-et')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('chatbot_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b31d2b12a8e3fd9c881a5a24e7147d0c74845586ee91bf16f1bd9f2a67f59324"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}